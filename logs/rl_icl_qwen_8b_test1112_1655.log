2025-11-12 16:55:47 - root - INFO - Logging setup complete. Outputting to console and file: logs/rl_icl_qwen_8b_test1112_1655.log
2025-11-12 16:55:47 - root - INFO - Initialized all random seeds to: 42
2025-11-12 16:55:47 - __main__ - INFO - Using device: cuda
2025-11-12 16:55:47 - __main__ - INFO - Starting run: 1112_1655
2025-11-12 16:55:47 - __main__ - INFO - --- Initializing Models ---
2025-11-12 16:55:47 - root - INFO - [EmbeddingModel] Loading embedding model: all-MiniLM-L6-v2...
2025-11-12 16:55:47 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-12 16:56:26 - root - INFO - [EmbeddingModel] Model loaded. Embedding dimension: 384
2025-11-12 16:56:26 - models.llm_wrapper - INFO - Loading LLM environment: Qwen/Qwen3-8B...
2025-11-12 16:56:38 - models.llm_wrapper - INFO - LLM 'Qwen/Qwen3-8B' loaded successfully.
2025-11-12 16:56:38 - data_utils.mtop_loader - INFO - --- Creating Corpus (Action Space) ---
2025-11-12 16:56:38 - data_utils.mtop_loader - INFO - Loading full 'train' split (no global cache used)...
2025-11-12 16:56:55 - data_utils.mtop_loader - INFO - Loading EmbeddingModel (all-MiniLM-L6-v2) for K-Means/Sampling...
2025-11-12 16:56:55 - root - INFO - [EmbeddingModel] Loading embedding model: all-MiniLM-L6-v2...
2025-11-12 16:56:55 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-12 16:57:06 - root - INFO - [EmbeddingModel] Model loaded. Embedding dimension: 384
2025-11-12 16:57:06 - data_utils.mtop_loader - INFO - Pre-computing all training data embeddings...
2025-11-12 16:57:08 - data_utils.mtop_loader - INFO - Full train data and embeddings loaded (15667 samples).
2025-11-12 16:57:08 - data_utils.mtop_loader - WARNING - USE_CLUSTERED_CORPUS=False. Using the *entire* training dataset (15667 samples) as corpus.
2025-11-12 16:57:08 - data_utils.mtop_loader - INFO - Corpus created. Final size: 15667
2025-11-12 16:57:08 - __main__ - INFO - Corpus embeddings computed. Shape: torch.Size([15667, 384])
2025-11-12 16:57:08 - data_utils.mtop_loader - INFO - Loading query dataloader (split=train, batch_size=16, shuffle=True, nums=5000)...
2025-11-12 16:57:12 - data_utils.mtop_loader - INFO - Randomly sampling 5000 examples for 'train' split...
2025-11-12 16:57:12 - data_utils.mtop_loader - INFO - Loading query dataloader (split=dev, batch_size=64, shuffle=False, nums=128)...
2025-11-12 16:57:14 - data_utils.mtop_loader - INFO - Randomly sampling 128 examples for 'dev' split...
2025-11-12 16:57:14 - root - INFO - sytem prompt is You are an expert assistant for semantic parsing. Given a user utterance, you must convert it into its logical form representation.
2025-11-12 16:57:33 - __main__ - INFO - Accuracy: 48.44% (62/128), Avg NLL: 0.0079
2025-11-12 16:57:33 - __main__ - INFO - Saving evaluation results to file...
2025-11-12 16:57:33 - __main__ - INFO - Evaluation results saved to: results/rl_icl_qwen_8b_test/1112_1655/val_results_test.csv
2025-11-12 16:57:33 - root - INFO - sytem prompt is Letâ€™s translate sentences in natural language into its logical form representation.
2025-11-12 16:57:52 - __main__ - INFO - Accuracy: 42.19% (54/128), Avg NLL: 0.0089
2025-11-12 16:57:52 - __main__ - INFO - Saving evaluation results to file...
2025-11-12 16:57:52 - __main__ - INFO - Evaluation results saved to: results/rl_icl_qwen_8b_test/1112_1655/val_results_test.csv
