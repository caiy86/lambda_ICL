2025-11-12 16:59:53 - root - INFO - Logging setup complete. Outputting to console and file: logs/rl_icl_qwen_8b_test1112_1659.log
2025-11-12 16:59:53 - root - INFO - Initialized all random seeds to: 42
2025-11-12 16:59:53 - __main__ - INFO - Using device: cuda
2025-11-12 16:59:53 - __main__ - INFO - Starting run: 1112_1659
2025-11-12 16:59:53 - __main__ - INFO - --- Initializing Models ---
2025-11-12 16:59:53 - root - INFO - [EmbeddingModel] Loading embedding model: all-MiniLM-L6-v2...
2025-11-12 16:59:53 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-12 17:00:01 - root - INFO - [EmbeddingModel] Model loaded. Embedding dimension: 384
2025-11-12 17:00:01 - models.llm_wrapper - INFO - Loading LLM environment: Qwen/Qwen3-8B...
2025-11-12 17:00:07 - models.llm_wrapper - INFO - LLM 'Qwen/Qwen3-8B' loaded successfully.
2025-11-12 17:00:07 - data_utils.mtop_loader - INFO - --- Creating Corpus (Action Space) ---
2025-11-12 17:00:07 - data_utils.mtop_loader - INFO - Loading full 'train' split (no global cache used)...
2025-11-12 17:00:13 - data_utils.mtop_loader - INFO - Loading EmbeddingModel (all-MiniLM-L6-v2) for K-Means/Sampling...
2025-11-12 17:00:13 - root - INFO - [EmbeddingModel] Loading embedding model: all-MiniLM-L6-v2...
2025-11-12 17:00:13 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2025-11-12 17:00:19 - root - INFO - [EmbeddingModel] Model loaded. Embedding dimension: 384
2025-11-12 17:00:19 - data_utils.mtop_loader - INFO - Pre-computing all training data embeddings...
2025-11-12 17:00:22 - data_utils.mtop_loader - INFO - Full train data and embeddings loaded (15667 samples).
2025-11-12 17:00:22 - data_utils.mtop_loader - WARNING - USE_CLUSTERED_CORPUS=False. Using the *entire* training dataset (15667 samples) as corpus.
2025-11-12 17:00:22 - data_utils.mtop_loader - INFO - Corpus created. Final size: 15667
2025-11-12 17:00:22 - __main__ - INFO - Corpus embeddings computed. Shape: torch.Size([15667, 384])
2025-11-12 17:00:22 - data_utils.mtop_loader - INFO - Loading query dataloader (split=train, batch_size=16, shuffle=True, nums=5000)...
2025-11-12 17:00:27 - data_utils.mtop_loader - INFO - Randomly sampling 5000 examples for 'train' split...
2025-11-12 17:00:27 - data_utils.mtop_loader - INFO - Loading query dataloader (split=dev, batch_size=64, shuffle=False, nums=128)...
2025-11-12 17:00:29 - data_utils.mtop_loader - INFO - Randomly sampling 128 examples for 'dev' split...
2025-11-12 17:00:29 - root - INFO - sytem prompt is Given a user utterance, you must convert it into its logical form representation.
2025-11-12 17:00:47 - __main__ - INFO - Accuracy: 46.88% (60/128), Avg NLL: 0.0071
2025-11-12 17:00:47 - __main__ - INFO - Saving evaluation results to file...
2025-11-12 17:00:47 - __main__ - INFO - Evaluation results saved to: results/rl_icl_qwen_8b_test/1112_1659/val_results_test.csv
2025-11-12 17:00:47 - root - INFO - sytem prompt is You are an expert assistant for semantic parsing. Letâ€™s translate sentences in natural language into its logical form representation.
2025-11-12 17:01:06 - __main__ - INFO - Accuracy: 44.53% (57/128), Avg NLL: 0.0095
2025-11-12 17:01:06 - __main__ - INFO - Saving evaluation results to file...
2025-11-12 17:01:06 - __main__ - INFO - Evaluation results saved to: results/rl_icl_qwen_8b_test/1112_1659/val_results_test.csv
